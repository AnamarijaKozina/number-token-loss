{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T13:25:06.765512Z",
     "start_time": "2024-07-13T13:24:51.350805Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "### Huggingface dataset and tokenizer imports\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import XLNetTokenizer\n",
    "\n",
    "from src.tokenizer.xval_tokenizer import XvalTokenizer\n",
    "from src.transformer_backbone.xlnet import XLNetBackbone\n",
    "from src.encoding_decoding.xval_encoding_decoding import XValModel, define_masked_num_collator as xval_define_masked_num_collator\n",
    "\n",
    "from src.tokenizer.rt_tokenizer import RtTokenizer\n",
    "from src.encoding_decoding.rt_encoding_decoding import RegressionTransformer, define_masked_num_collator as rt_define_masked_num_collator\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5Model, T5ForConditionalGeneration\n",
    "import torch\n",
    "import torch.nn as nn"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-13T13:25:12.720219Z",
     "start_time": "2024-07-13T13:25:09.934526Z"
    }
   },
   "id": "b0b345b3445aaf55",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jonas\\anaconda3\\envs\\xval\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "90067010121940f7b304535d735109eb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jonas\\anaconda3\\envs\\xval\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Jonas\\.cache\\huggingface\\hub\\models--t5-small. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "883dcc7b3bd049d793ca3f5334c0af9a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-13T13:25:35.511700Z",
     "start_time": "2024-07-13T13:25:12.727993Z"
    }
   },
   "id": "5a1f6e4ccf1a8a22",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embedding dimension will be 33000. This might induce some performance reduction as *Tensor Cores* will not be available. For more details about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "data": {
      "text/plain": "Embedding(33000, 512)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(33_000)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-13T13:26:59.352756Z",
     "start_time": "2024-07-13T13:26:58.981838Z"
    }
   },
   "id": "37584c035075e299",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'T5ForConditionalGeneration' object has no attribute 'transformer'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransformer\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\xval\\lib\\site-packages\\torch\\nn\\modules\\module.py:1614\u001B[0m, in \u001B[0;36mModule.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   1612\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m modules:\n\u001B[0;32m   1613\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m modules[name]\n\u001B[1;32m-> 1614\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m   1615\u001B[0m     \u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, name))\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'T5ForConditionalGeneration' object has no attribute 'transformer'"
     ]
    }
   ],
   "source": [
    "model.transformer"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-13T13:28:18.124419Z",
     "start_time": "2024-07-13T13:28:17.930628Z"
    }
   },
   "id": "d25f5d26deb47d96",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from transformers import XLNetModel"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-13T13:28:39.730698Z",
     "start_time": "2024-07-13T13:28:39.491816Z"
    }
   },
   "id": "24ebbd9d19c9338a",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "xlnet = XLNetModel.from_pretrained(\"xlnet-base-cased\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-13T13:28:56.765952Z",
     "start_time": "2024-07-13T13:28:55.602640Z"
    }
   },
   "id": "c81c7bce179c279a",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'XLNetModel' object has no attribute 'pos_embedding'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mxlnet\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpos_embedding\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\xval\\lib\\site-packages\\torch\\nn\\modules\\module.py:1614\u001B[0m, in \u001B[0;36mModule.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   1612\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m modules:\n\u001B[0;32m   1613\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m modules[name]\n\u001B[1;32m-> 1614\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[0;32m   1615\u001B[0m     \u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m, name))\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'XLNetModel' object has no attribute 'pos_embedding'"
     ]
    }
   ],
   "source": [
    "xlnet.pos_embedding"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-13T13:29:41.613433Z",
     "start_time": "2024-07-13T13:29:41.347965Z"
    }
   },
   "id": "59622bcdbdfce0ac",
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Load dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "972c6bb08541c62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T18:44:51.544532Z",
     "start_time": "2024-07-07T18:44:51.342216Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a function to read the text file and yield examples\n",
    "def read_txt(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    for i in range(0, len(lines), 2):\n",
    "        question = lines[i].strip()\n",
    "        answer = lines[i+1].strip()\n",
    "        yield {'question': question, 'answer': answer}\n",
    "\n",
    "# Define the dataset loading function\n",
    "def load_txt_dataset(file_path):\n",
    "    return Dataset.from_generator(read_txt, gen_kwargs={'file_path': file_path})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a43a0143e570d4f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T18:44:52.367977Z",
     "start_time": "2024-07-07T18:44:52.165857Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cca47045ecce4f31ac678c2e697bd74c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer'],\n",
       "    num_rows: 117\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = './data/mathematics_dataset-v1.0/mathematics_dataset-v1.0/train-easy/algebra__linear_1d_small.txt'\n",
    "\n",
    "ds = load_txt_dataset(data_path)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5eeb30d4c54bafe5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T18:44:53.898916Z",
     "start_time": "2024-07-07T18:44:53.687811Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Solve 0 = 4*b + b + 15 for b.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"question\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86262376ecabca53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T18:44:54.975602Z",
     "start_time": "2024-07-07T18:44:54.752247Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-3'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"answer\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bc3538d10a02c9",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Load pretrained Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8aef0cc1850ecd0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T18:45:01.201049Z",
     "start_time": "2024-07-07T18:44:57.916088Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jonas\\anaconda3\\envs\\xval\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = \"xlnet-base-cased\"\n",
    "pretrained_tokenizer = XLNetTokenizer.from_pretrained(model_name)\n",
    "transformer_backbone = XLNetBackbone(model_name).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bf788e466c764",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Xval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ff4eaf104d230a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T18:45:02.426583Z",
     "start_time": "2024-07-07T18:45:02.301065Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number token ID: 32000\n"
     ]
    }
   ],
   "source": [
    "tokenizer = XvalTokenizer(pretrained_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75805a22e73ef981",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T18:45:03.436001Z",
     "start_time": "2024-07-07T18:45:03.253708Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenized_x = tokenizer(ds[0][\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e65bb8917b18364",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T18:45:04.581141Z",
     "start_time": "2024-07-07T18:45:04.431137Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solve 0 = 4*b + b + 15 for b.\n",
      "['Sol', 've', '[NUM]', '=', '[NUM]', '*', 'b', '+', '', 'b', '+', '[NUM]', 'for', '', 'b', '.', '<sep>', '<cls>']\n",
      "[1.0, 1.0, 0.0, 1.0, 4.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 15.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(ds[0][\"question\"])\n",
    "print([tokenizer.tokenizer.decode(x) for x in tokenized_x[\"input_ids\"]])\n",
    "print([x for x in tokenized_x[\"numbers\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb82958cbc325764",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T18:45:06.227585Z",
     "start_time": "2024-07-07T18:45:05.902582Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting tokenization...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a8fbc6c22a84402919e9ce46e5635af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/117 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nStarting tokenization...\")\n",
    "tokenize_lambda = lambda x: {\"question\": tokenizer(x[\"question\"]), \"answer\": tokenizer(x[\"answer\"])}\n",
    "tokenized_ds = ds.map(\n",
    "    tokenize_lambda,\n",
    "    batched=False,\n",
    "    # num_proc=30,\n",
    "    load_from_cache_file=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f20637e1e61277ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T18:45:18.817677Z",
     "start_time": "2024-07-07T18:45:18.116404Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = XValModel(transformer_backbone=transformer_backbone, vocab_size=len(tokenizer.tokenizer), dim_feedforward=1536, context_length=955).cuda()\n",
    "\n",
    "pad_token_id = tokenizer.tokenizer.pad_token_id\n",
    "mask_token_id = tokenizer.tokenizer.mask_token_id\n",
    "mlm_probability = 0.3\n",
    "epochs = 10\n",
    "lr = 1e-4\n",
    "weight_decay = 0.01\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "collator = xval_define_masked_num_collator(pad_token_id, mask_token_id, mlm_probability)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    tokenized_ds[\"question\"],\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    collate_fn=collator,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce76f62915627ec5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T18:46:38.610557Z",
     "start_time": "2024-07-07T18:45:19.860560Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:06<00:57,  6.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0: loss_mlm = 11.248; loss_num = 51407.855; loss_total = 51419.104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:13<00:55,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1: loss_mlm = 11.126; loss_num = 81999.289; loss_total = 82010.416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:22<00:53,  7.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #2: loss_mlm = 10.889; loss_num = 82899.489; loss_total = 82910.380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:30<00:46,  7.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #3: loss_mlm = 10.618; loss_num = 82658.826; loss_total = 82669.446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:39<00:42,  8.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #4: loss_mlm = 10.362; loss_num = 124809.849; loss_total = 124820.213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:48<00:34,  8.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #5: loss_mlm = 10.089; loss_num = 159113.855; loss_total = 159123.946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:56<00:24,  8.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #6: loss_mlm = 9.815; loss_num = 156969.954; loss_total = 156979.772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [01:03<00:16,  8.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #7: loss_mlm = 9.553; loss_num = 158357.218; loss_total = 158366.772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [01:11<00:07,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #8: loss_mlm = 9.294; loss_num = 152996.410; loss_total = 153005.706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:18<00:00,  7.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #9: loss_mlm = 9.044; loss_num = 149240.996; loss_total = 149250.042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loss_hist = []\n",
    "loss_mlm_hist = []\n",
    "loss_num_hist = []\n",
    "\n",
    "max_n_batches = 100\n",
    "\n",
    "try:\n",
    "    for e in tqdm(range(epochs)):\n",
    "        n_batches = 0\n",
    "        for batch in train_loader:\n",
    "            if n_batches > max_n_batches:\n",
    "                break\n",
    "            logit_preds, num_preds = model(\n",
    "                batch[\"x\"].cuda(),\n",
    "                batch[\"x_num\"].cuda(),\n",
    "                batch[\"attention_mask\"].cuda(),\n",
    "                batch[\"token_type_ids\"].cuda(),\n",
    "            )\n",
    "            with torch.autocast(device_type=\"cuda\"):\n",
    "                loss_mlm = F.cross_entropy(\n",
    "                    logit_preds.view(-1, logit_preds.size(-1)),\n",
    "                    batch[\"y\"].cuda().view(-1),\n",
    "                    ignore_index=-100,\n",
    "                    reduction=\"mean\",\n",
    "                )\n",
    "                num_mask = batch['y'] == tokenizer.tokenizer.convert_tokens_to_ids(\"[NUM]\")\n",
    "                loss_num = F.mse_loss(\n",
    "                    num_preds[num_mask],\n",
    "                    batch[\"y_num\"][num_mask].view(-1, 1).cuda(),\n",
    "                    reduction=\"mean\",\n",
    "                )\n",
    "            loss = loss_mlm + loss_num\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_hist.append(loss.item())\n",
    "            loss_mlm_hist.append(loss_mlm.item())\n",
    "            loss_num_hist.append(loss_num.item())\n",
    "            n_batches += 1\n",
    "\n",
    "            try:\n",
    "                loss_avg = 0.99 * loss_avg + 0.01 * loss.item()\n",
    "                loss_mlm_avg = 0.99 * loss_mlm_avg + 0.01 * loss_mlm.item()\n",
    "                loss_num_avg = 0.99 * loss_num_avg + 0.01 * loss_num.item()\n",
    "            except:\n",
    "                loss_avg = loss.item()\n",
    "                loss_mlm_avg = loss_mlm.item()\n",
    "                loss_num_avg = loss_num.item()\n",
    "\n",
    "        checkpoint = {\n",
    "            \"model\": model.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "            \"loss\": loss_avg,\n",
    "            \"loss_hist\": loss_hist,\n",
    "            \"loss_mlm_hist\": loss_mlm_hist,\n",
    "            \"loss_num_hist\": loss_num_hist,\n",
    "        }\n",
    "        torch.save(checkpoint, \"./ckpt.pt\")\n",
    "        print(f\"Epoch #{e}: loss_mlm = {loss_mlm_avg:.3f}; loss_num = {loss_num_avg:.3f}; loss_total = {loss_avg:.3f}\")\n",
    "except KeyboardInterrupt:\n",
    "    print('Interrupted')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10b217ca79fdbf3",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Regression Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "672989b5106f7d13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T18:50:19.751330Z",
     "start_time": "2024-07-07T18:50:19.518014Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_num_tokens(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    return [line.strip() for line in lines]\n",
    "\n",
    "num_tokens = read_num_tokens(\"regression_transformer_number_tokens.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c99ec783ffb8b291",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T18:50:20.346729Z",
     "start_time": "2024-07-07T18:50:20.194606Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_0_0_', '_1_0_', '_2_0_', '_3_0_', '_4_0_']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a628e81c204ef57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T18:50:21.026171Z",
     "start_time": "2024-07-07T18:50:20.882772Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenizer = RtTokenizer(pretrained_tokenizer, num_tokens, embedding_dim=transformer_backbone.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78c7b66f6dc69c4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T18:50:21.791106Z",
     "start_time": "2024-07-07T18:50:21.631155Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solve 0 = 4*b + b + 15 for b.\n"
     ]
    }
   ],
   "source": [
    "print(ds[0][\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3ce7bbb3a3f2821",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T18:50:22.818744Z",
     "start_time": "2024-07-07T18:50:22.614624Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solve 0 = 4*b + b + 15 for b.\n",
      "['Sol', 've', '_0_0_', '=', '_4_0_', '*', 'b', '+', '', 'b', '+', '_1_1_', '_5_0_', 'for', '', 'b', '.', '<sep>', '<cls>']\n",
      "[0.0, 0.0, 0.0, 0.0, 2.7699864, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.9249663, 3.4624832, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "tokenized_x = tokenizer(ds[0][\"question\"])\n",
    "print(ds[0][\"question\"])\n",
    "print([tokenizer.tokenizer.decode(x) for x in tokenized_x[\"input_ids\"]])\n",
    "print([x.sum() for x in tokenized_x[\"number_embeddings\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "423fea9a7bd46a45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T18:50:26.555983Z",
     "start_time": "2024-07-07T18:50:25.826365Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting tokenization...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "406476198d0b48c8b30eb2ae0f58c3f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/117 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"\\nStarting tokenization...\")\n",
    "tokenize_lambda = lambda x: {\"question\": tokenizer(x[\"question\"]), \"answer\": tokenizer(x[\"answer\"])}\n",
    "tokenized_ds = ds.map(\n",
    "    tokenize_lambda,\n",
    "    batched=False,\n",
    "    # num_proc=30,\n",
    "    load_from_cache_file=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d895cb7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9faddff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Initialize our Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset if training_args.do_train else None,\n",
    "        eval_dataset=eval_dataset if training_args.do_eval else None,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics if training_args.do_eval and not is_torch_xla_available() else None,\n",
    "        preprocess_logits_for_metrics=preprocess_logits_for_metrics\n",
    "        if training_args.do_eval and not is_torch_xla_available()\n",
    "        else None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a879c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2856ff1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e1447c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e919f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac466b2397ff20ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T18:50:28.589883Z",
     "start_time": "2024-07-07T18:50:27.075860Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = RegressionTransformer(transformer_backbone=transformer_backbone, vocab_size=len(tokenizer.tokenizer), dim_feedforward=1536,\n",
    "                  context_length=955).cuda()\n",
    "\n",
    "pad_token_id = tokenizer.tokenizer.pad_token_id\n",
    "mask_token_id = tokenizer.tokenizer.mask_token_id\n",
    "mlm_probability = 0.3\n",
    "epochs = 10\n",
    "lr = 1e-4\n",
    "weight_decay = 0.01\n",
    "optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "collator = rt_define_masked_num_collator(pad_token_id, mask_token_id, mlm_probability)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    tokenized_ds[\"question\"],\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    collate_fn=collator,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd75124d4f0b53ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-07T18:53:11.737055Z",
     "start_time": "2024-07-07T18:50:29.190812Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:19<02:59, 19.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #0: loss = 143369.369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:36<02:25, 18.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1: loss = 137720.320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:56<02:10, 18.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #2: loss = 132293.795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [01:13<01:47, 17.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #3: loss = 127081.060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [01:27<01:23, 16.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #4: loss = 122073.714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [01:49<01:13, 18.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #5: loss = 117263.670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [02:02<00:49, 16.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #6: loss = 112643.155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [02:16<00:31, 15.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #7: loss = 108204.702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [02:29<00:14, 14.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #8: loss = 103941.141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:42<00:00, 16.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #9: loss = 99845.585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "loss_hist = []\n",
    "\n",
    "max_n_batches = 100\n",
    "\n",
    "try:\n",
    "    for e in tqdm(range(epochs)):\n",
    "        n_batches = 0\n",
    "        for batch in train_loader:\n",
    "            if n_batches > max_n_batches:\n",
    "                break\n",
    "            logit_preds = model(\n",
    "                batch[\"x\"].cuda(),\n",
    "                batch[\"number_embeddings\"].cuda(),\n",
    "                batch[\"attention_mask\"].cuda(),\n",
    "                batch[\"token_type_ids\"].cuda(),\n",
    "            )\n",
    "            with torch.autocast(device_type=\"cuda\"):\n",
    "                loss = F.cross_entropy(\n",
    "                    logit_preds.view(-1, logit_preds.size(-1)),\n",
    "                    batch[\"y\"].cuda().view(-1),\n",
    "                    ignore_index=-100,\n",
    "                    reduction=\"mean\",\n",
    "                )\n",
    "               \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_hist.append(loss.item())\n",
    "            n_batches += 1\n",
    "\n",
    "            try:\n",
    "                loss_avg = 0.99 * loss_avg + 0.01 * loss.item()\n",
    "            except:\n",
    "                loss_avg = loss.item()\n",
    "\n",
    "        checkpoint = {\n",
    "            \"model\": model.state_dict(),\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "            \"loss\": loss_avg,\n",
    "            \"loss_hist\": loss_hist,\n",
    "        }\n",
    "        torch.save(checkpoint, \"./ckpt.pt\")\n",
    "        print(f\"Epoch #{e}: loss = {loss_avg:.3f}\")\n",
    "except KeyboardInterrupt:\n",
    "    print('Interrupted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b064a020a15d1f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
